「マルチエージェント強化学習における分散実行型方策獲得に関する研究」

近年、マルチロボット環境をはじめとする複数主体による協調的タスク遂行が求められる場面が増加しており、それに対応するための手法としてマルチエージェント強化学習（MARL: Multi-Agent Reinforcement Learning）が注目されている。
MARLでは、全エージェントの観測情報を統合して意思決定を行う中央実行型（centralized execution）と、各エージェントが自らの局所観測に基づいて意思決定を行う分散実行型（decentralized execution）の二つの枠組みが存在する。
中央実行型は、局所観測による不確実性を回避できるため高い性能を発揮する一方、実環境では通信制約やスケーラビリティの問題から適用が困難である。
一方の分散実行型は、通信制約下でも動作可能であるが、局所観測に基づく意思決定のため、中央実行型と比べて性能が劣る傾向にある。
本研究では、中央実行型モデルの性能を維持しつつ、分散実行型エージェントへ知識を転移するための方策蒸留手法を提案する。
これにより、中央実行型の優れた協調戦略を、通信制約のある環境でも実行可能な分散方策として実現することを目的とする。



目次

１章
序論

マルチロボット環境とMARLの重要性
研究背景
研究の目的と貢献

研究背景

RLの定式化とか前提
MARLの定式化とか前提
Transformer（MAT）


２章
現状の課題
要求機能

３章
関連研究

MARLの既存手法
ポリシー蒸留
本研究の位置付け　具体的な差分

４章
提案手法
要求機能
パイプライン



５章
実験と考察
環境タスク説明
比較手法
結果
考察

６章
結論と展望

謝辞

参考文献

補遺
ハイパラ
擬似こーど
追加実験
タスク詳細
計算環境



メモ

引用はTEXがらく
３、４、５、、、

