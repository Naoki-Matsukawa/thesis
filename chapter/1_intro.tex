\chapter{序論}
\label{chap:introduction}

\section{研究の背景}
\label{sec:intro}

% LuaLaTeX用の修論テンプレートです．英語で書きたい場合は\texttt{thesis.tex}の冒頭の英語用の設定を有効にし，日本語用の設定を消してください．
% \begin{itemize}
%   \item このテンプレートを使うとLuaLaTeXでコンパイルできます．
%   \item vscodeで書くこともできます．
%   \item 適当に作ったので動作は保証しません．
% \end{itemize}

近年の産業において、マルチロボット環境が増加しており、ロボットを協調的に制御する技術の重要性が高まっている。複数のロボットが同時に動く環境において、ルールベースの制御手法では、ロボット間の複雑な相互作用を十分に捉えることが難しい。そのため、強化学習（Reinforcement Learning: RL）の中でも特に、複数のエージェントを同じ環境で学習させる、マルチエージェント強化学習（Multi-Agent Reinforcement Learning: MARL）が注目されている。単一のエージェントを学習させる場合と比較して、マルチエージェント強化学習においては、各エージェントが他のエージェントの行動に影響を受けるため、環境が非定常となり、学習が困難になるという課題がある。また、各エージェントがそれぞれの行動空間を持つため、状態空間や行動空間が指数関数的に増加し、スケーラビリティの問題も存在する。

\section{研究の目的と貢献}
本研究の目的は、中央実行が前提となっている手法の協調性能を維持したまま、分散実行を可能にする手法を提案することである。 具体的には、中央実行型エージェントの方策を分散実行型エージェントに蒸留することで、通信制約のある環境下でも高い協調性能を発揮できる分散実行型方策を獲得することを目指す。本研究の主な貢献は以下の通りである。
